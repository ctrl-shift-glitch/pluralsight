{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUDASemantics.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hIaq0ODZgVMO","colab_type":"code","colab":{}},"source":["import torch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g3C5kguagZNH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2628b16e-fb1d-40ef-8a60-de073d63d933","executionInfo":{"status":"ok","timestamp":1562554518935,"user_tz":420,"elapsed":375,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["torch.cuda.is_available()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"JZxCEWgegd9_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0a4e3742-2660-49ce-c368-4085ad6035ba","executionInfo":{"status":"ok","timestamp":1562554538798,"user_tz":420,"elapsed":395,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["torch.cuda.current_device()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"tVcEcTcdgDT1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"91f250db-438e-4b1f-cf14-ea14915ecfe5","executionInfo":{"status":"ok","timestamp":1562554541823,"user_tz":420,"elapsed":366,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["torch.cuda.device_count()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"jM1k1MpggrA-","colab_type":"text"},"source":["Check how much memory tensors are allocated"]},{"cell_type":"code","metadata":{"id":"6dkDxCGEgSCo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"85cdde57-d65c-4e85-d9bd-142e64d09c09","executionInfo":{"status":"ok","timestamp":1562554600505,"user_tz":420,"elapsed":397,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["torch.cuda.memory_allocated()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"TB-CHlkDg3nU","colab_type":"text"},"source":["Behind the scenes PyTorch uses a **caching memery allocator** to speed up memory allocations - this allows fast memory deallocation without device synchronizations"]},{"cell_type":"code","metadata":{"id":"D0rjQ8NegUPE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b6fd7ddd-1137-4422-fc78-9a704705f242","executionInfo":{"status":"ok","timestamp":1562554886888,"user_tz":420,"elapsed":277,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["torch.cuda.memory_cached()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Ai9WGNKUiJtc","colab_type":"text"},"source":["Find the current CUDA device being used"]},{"cell_type":"code","metadata":{"id":"MzCFaZt0h2md","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"865bbb66-e84d-425a-988b-9afc3a7e5017","executionInfo":{"status":"ok","timestamp":1562555009738,"user_tz":420,"elapsed":408,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["cuda = torch.device('cuda')\n","cuda"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"pAZZu-bJieg9","colab_type":"text"},"source":["Accessing multiple GPUs for CUDA context manager"]},{"cell_type":"code","metadata":{"id":"KYEv48gEiRxk","colab_type":"code","colab":{}},"source":["cuda0 = torch.device('cuda:0')\n","cuda1 = torch.device('cuda:1')\n","cuda2 = torch.device('cuda:2')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ExAXJo2OjeUq","colab_type":"text"},"source":["By default tensors are created on CPU"]},{"cell_type":"code","metadata":{"id":"nzhFAJeJir7L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"090978ae-d1cf-47ed-b964-559ab1cc2291","executionInfo":{"status":"ok","timestamp":1562555347535,"user_tz":420,"elapsed":477,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["x = torch.tensor([10., 20.])\n","x"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10., 20.])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"8gn7fnSpjuFH","colab_type":"text"},"source":["Create a tensor on default cuda device"]},{"cell_type":"code","metadata":{"id":"LGhn9ejgjnA4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"88ce8549-5bb5-4e29-890e-82e200e63c57","executionInfo":{"status":"ok","timestamp":1562555613662,"user_tz":420,"elapsed":576,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["x_default = torch.tensor([10., 20.], device=cuda)\n","x_default"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10., 20.], device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"zBR2pwSCkqcz","colab_type":"text"},"source":["Create a device on a specific CUDA device"]},{"cell_type":"code","metadata":{"id":"__0AnO5dkmJ9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"91449c10-8528-4d67-c0ca-905f724bbb8c","executionInfo":{"status":"ok","timestamp":1562555913286,"user_tz":420,"elapsed":381,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["x0 = torch.tensor([10., 20.], device=cuda0)\n","x0"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10., 20.], device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"pdoHnwH9lt6S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"outputId":"d5ad4b16-86ed-4016-e462-9205ca25a7e4","executionInfo":{"status":"error","timestamp":1562555936226,"user_tz":420,"elapsed":313,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["x1 = torch.tensor([10., 20.], device=cuda1)\n"],"execution_count":18,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-bd9d9f8a9619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal"]}]},{"cell_type":"markdown","metadata":{"id":"_EePzws__Eg9","colab_type":"text"},"source":[".cuda() function creates a copy of the object in the memory. If the tensor is already in CUDA memory and on the correct device then no copy is performed\n","\n","Here x was originally created on the CPU and is not on the default device in CUDA memory"]},{"cell_type":"code","metadata":{"id":"--AWoRZNl2xq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ac8846e3-f130-4ccd-f3f1-044814518f08","executionInfo":{"status":"ok","timestamp":1562563033186,"user_tz":420,"elapsed":378,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["y = x.cuda()\n","\n","y\n"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10., 20.], device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"ZWRuCrLMBB40","colab_type":"text"},"source":["If x1 tensor is on GPU1 and you want to make a copy available on another device then you would want to use cuda()\n","\n","Here x1 was originally created on cuda:1, a copy will now be made on the default device cuda:0"]},{"cell_type":"code","metadata":{"id":"3Cxu_ZttA3iT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1c22feb7-76bf-4535-f1af-12053628323d","executionInfo":{"status":"ok","timestamp":1562563340012,"user_tz":420,"elapsed":351,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["y0 = x0.cuda()\n","\n","y0"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10., 20.], device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"ggw0mZFVCjnl","colab_type":"text"},"source":["\"with\" context allow you to create a black in which only one GPU device is valid"]},{"cell_type":"code","metadata":{"id":"_Th_X79rB_0g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"c2db2cbe-1a03-4fef-ff2e-91b9d5cad273","executionInfo":{"status":"ok","timestamp":1562563739517,"user_tz":420,"elapsed":396,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["print('Outside with context: ', torch.cuda.current_device())\n","\n","with torch.cuda.device(0): #Put (1) in the brackets for GPU1\n","    print('Inside with context: ', torch.cuda.current_device())\n","    \n","print('Outside with context again: ', torch.cuda.current_device())"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Outside with context:  0\n","Inside with context:  0\n","Outside with context again:  0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PVVU_KbcFTaK","colab_type":"text"},"source":["When we explicitly specify a device within a with context the tensor is created on the specified device"]},{"cell_type":"code","metadata":{"id":"myOtnPNsDZJT","colab_type":"code","colab":{}},"source":["with torch.cuda.device(0): #Put (1) in the brackets\n","  \n","    a = torch.tensor([10., 20.])  #This tensor will be created on GPU1 coz 1 is mentioned in torch.cuda.device(1)\n","    \n","    a0 = torch.tensor([10., 20.], device=cuda0) #This tensor will be created on GPU0\n","    \n","    a1 = torch.tensor([10., 20.], device=cuda) #This tensor will be created on default GPU and in this with block it is GPU1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvyswCkvGlr0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"87864ab8-ad3f-4ad5-fc6b-a1c4f24bdf24","executionInfo":{"status":"ok","timestamp":1562565111947,"user_tz":420,"elapsed":374,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["a"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([10., 20.])"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"YynkIqIxJKCo","colab_type":"text"},"source":["Operations cannot be performed on tensors on different CUDA devices"]},{"cell_type":"code","metadata":{"id":"ZuivXUrEIVNd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"outputId":"821cf3bf-d5a3-4b18-ccad-77362dd53710","executionInfo":{"status":"error","timestamp":1562565391478,"user_tz":420,"elapsed":370,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["sum_a = a + a0"],"execution_count":40,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-e4ab1d679b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: expected backend CPU and dtype Float but got backend CUDA and dtype Float"]}]},{"cell_type":"code","metadata":{"id":"7ajVTl3lJ7LI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"573623cd-1214-43a3-baeb-2ddbcfbcb5a8","executionInfo":{"status":"ok","timestamp":1562565577133,"user_tz":420,"elapsed":373,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["torch.cuda.memory_allocated()"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3072"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"sSoy5iJOKofv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"62c6974d-8d6c-4361-adbc-81e6d5b781ac","executionInfo":{"status":"ok","timestamp":1562565619842,"user_tz":420,"elapsed":489,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["torch.cuda.memory_cached()"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2097152"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"qHBJyUkJKsqu","colab_type":"code","colab":{}},"source":["torch.cuda.empty_cache()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nD6eQnlTK9Y0","colab_type":"text"},"source":["Copying tensor on same device. For example copying tensor from CPU to CPU and from GPU to GPU"]},{"cell_type":"code","metadata":{"id":"9axvArW-Kw3-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"a552b3cb-ff2b-48b3-ed39-b806a16ad093","executionInfo":{"status":"ok","timestamp":1562565776026,"user_tz":420,"elapsed":370,"user":{"displayName":"Punj Teer","photoUrl":"","userId":"17462811001222152653"}}},"source":["preserve_context = x.new_full([2, 2], fill_value=1.1)\n","preserve_context"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.1000, 1.1000],\n","        [1.1000, 1.1000]])"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"xunsU0RGLW0E","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}